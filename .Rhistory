NEI_motor[NEI_motor$fips == "24510","fips"] <- "Baltimore City"
transform?
?transform
table(NEI_motor$fips)
NEI_motor[NEI_motor$fips == "06037","fips"] <- "Los Angeles County"
table(NEI_motor$fips)
ggplot(NEI_motor, aes(year, Emissions, group=fips)) +
geom_line(stat = "summary", fun.y = "sum", color="blue") +
geom_point(stat = "summary", fun.y = "sum", color="blue", size = 2) +
ggtitle("Emissions from Motor Vehicles") +
ylab(expression("PM"[2.5] * " Emmisions (tons)"))
ggplot(NEI_motor, aes(year, Emissions, group=fips)) +
geom_line(stat = "summary", fun.y = "sum", color=fips) +
geom_point(stat = "summary", fun.y = "sum", color=fips, size = 2) +
ggtitle("Emissions from Motor Vehicles") +
ylab(expression("PM"[2.5] * " Emmisions (tons)"))
ggplot(NEI_motor, aes(year, Emissions, group=fips)) +
geom_line(stat = "summary", fun.y = "sum", aes(color=fips)) +
geom_point(stat = "summary", fun.y = "sum", aes(color=fips), size = 2) +
ggtitle("Emissions from Motor Vehicles") +
ylab(expression("PM"[2.5] * " Emmisions (tons)"))
BaltimoreNEI <- subset(NEI, fips == "24510")
SCC_motor <- SCC[grep("^Mobile(.)+Vehicles",SCC$EI.Sector),c("SCC","EI.Sector")]
NEI_motor <- merge(BaltimoreNEI, SCC_motor, all = FALSE)
library(ggplot2)
png("plot5.png")
ggplot(NEI_motor, aes(year, Emissions, group=1)) +
geom_line(stat = "summary", fun.y = "sum", color="blue") +
geom_point(stat = "summary", fun.y = "sum", color="blue", size = 2) +
ggtitle("Emissions from Motor Vehicles") +
ylab(expression("PM"[2.5] * " Emmisions (tons)"))
dev.off()
ggplot(NEI_motor, aes(year, Emissions, group=1)) +
geom_line(stat = "summary", fun.y = "sum", color="blue") +
geom_point(stat = "summary", fun.y = "sum", color="blue", size = 2) +
ggtitle("Emissions from Motor Vehicles") +
ylab(expression("PM"[2.5] * " Emmisions (tons)"))
NEI_Balt_LA <- subset(NEI, fips == "24510" | fips == "06037")
SCC_motor <- SCC[grep("^Mobile(.)+Vehicles",SCC$EI.Sector),c("SCC","EI.Sector")]
NEI_motor <- merge(NEI_Balt_LA, SCC_motor, all = FALSE)
NEI_motor[NEI_motor$fips == "24510","fips"] <- "Baltimore City"
NEI_motor[NEI_motor$fips == "06037","fips"] <- "Los Angeles County"
library(ggplot2)
png("plot6.png")
ggplot(NEI_motor, aes(year, Emissions, group=fips)) +
geom_line(stat = "summary", fun.y = "sum", aes(color=fips)) +
geom_point(stat = "summary", fun.y = "sum", aes(color=fips), size = 2) +
ggtitle("Emissions from Motor Vehicles") +
ylab(expression("PM"[2.5] * " Emmisions (tons)"))
dev.off()
ggplot(NEI_motor, aes(year, Emissions, group=fips)) +
geom_line(stat = "summary", fun.y = "sum", aes(color=fips)) +
geom_point(stat = "summary", fun.y = "sum", aes(color=fips), size = 2) +
ggtitle("Emissions from Motor Vehicles") +
ylab(expression("PM"[2.5] * " Emmisions (tons)"))
head(NEI_motor)
NEI_motor[1,2]
names(NEI_motor)[2] <- "County"
ggplot(NEI_motor, aes(year, Emissions, group=fips)) +
geom_line(stat = "summary", fun.y = "sum", aes(color=fips)) +
geom_point(stat = "summary", fun.y = "sum", aes(color=fips), size = 2) +
ggtitle("Emissions from Motor Vehicles") +
ylab(expression("PM"[2.5] * " Emmisions (tons)"))
ggplot(NEI_motor, aes(year, Emissions, group=County)) +
geom_line(stat = "summary", fun.y = "sum", aes(color=County)) +
geom_point(stat = "summary", fun.y = "sum", aes(color=County), size = 2) +
ggtitle("Emissions from Motor Vehicles") +
ylab(expression("PM"[2.5] * " Emmisions (tons)"))
NEI_Balt_LA <- subset(NEI, fips == "24510" | fips == "06037")
SCC_motor <- SCC[grep("^Mobile(.)+Vehicles",SCC$EI.Sector),c("SCC","EI.Sector")]
NEI_motor <- merge(NEI_Balt_LA, SCC_motor, all = FALSE)
NEI_motor[NEI_motor$fips == "24510","fips"] <- "Baltimore City"
NEI_motor[NEI_motor$fips == "06037","fips"] <- "Los Angeles County"
names(NEI_motor)[2] <- "County"
library(ggplot2)
png("plot6.png")
ggplot(NEI_motor, aes(year, Emissions, group=County)) +
geom_line(stat = "summary", fun.y = "sum", aes(color=County)) +
geom_point(stat = "summary", fun.y = "sum", aes(color=County), size = 2) +
ggtitle("Emissions from Motor Vehicles") +
ylab(expression("PM"[2.5] * " Emmisions (tons)"))
dev.off()
View(SCC)
View(NEI)
SCC_motor
SCC_motor$EI.Sector
unique(SCC_motor$EI.Sector)
setwd("~")
q()
rm(list=ls())
q()
library(dplyr)
?group_by
by_cyl <- mtcars %>% group_by(cyl)
by_cyl
mtcars
str(by_cul)
str(by_cyl)
str(mtcars)
rownames(mtcars)
by_cyl
by_cyl %>% summarise(
disp = mean(disp),
hp = mean(hp)
)
by_cyl %>% filter(disp == max(disp))
by_vs_am <- mtcars %>% group_by(vs, am)
by_vs <- by_vs_am %>% summarise(n = n())
by_vs
by_vs %>% summarise(n = sum(n))
by_vs %>%
ungroup() %>%
summarise(n = sum(n))
mtcars %>% group_by(vsam = vs + am)
by_cyl %>%
group_by(vs, am) %>%
group_vars()
by_cyl %>%
group_by(vs, am, add = TRUE) %>%
group_vars()
?spread
library(tidyr)
?spread
stocks <- data.frame(
time = as.Date('2009-01-01') + 0:9,
X = rnorm(10, 0, 1),
Y = rnorm(10, 0, 2),
Z = rnorm(10, 0, 4)
)
stocksm <- stocks %>% gather(stock, price, -time)
stocksm %>% spread(stock, price)
stocksm %>% spread(time, price)
stocks
stocksm
?gather
stocksm %>% spread(stock, price)
stocksm %>% spread(time, price)
stocksm %>% spread(time, price) %>% spread(stock, price)
?count
rm(list=ls())
library(janeaustenr)
library(dplyr)
library(stringr)
install.packages("janeaustinr")
library(stringr)
library(janeaustenr)
install.packages("janeaustenr")
library(janeaustenr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
library(tidyr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
library(tidytext)
install.packages("tidytext")
library(tidytext)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
View(tidy_books)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
View(tidy_books)
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing"))
View(tidy_books)
View(janeaustensentiment)
View(janeaustensentiment)
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment)
View(janeaustensentiment)
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing"))
View(janeaustensentiment)
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment)
View(janeaustensentiment)
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0)
View(janeaustensentiment)
janeaustensentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
View(janeaustensentiment)
library(ggplot2)
ggplot(janeaustensentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
ggplot(janeaustensentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2)
ggplot(janeaustensentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
sentiments
sentiments[sentiments$lexicon=="nrc"]
sentiments[sentiments$lexicon=="nrc",]
sentiments[sentiments$lexicon=="bing",]
sentiments[sentiments$lexicon=="nrc",]
sentiments[sentiments$lexicon=="bing",]
sentiments[sentiments$lexicon=="AFINN",]
pride_prejudice <- tidy_books %>%
filter(book == "Pride & Prejudice")
pride_prejudice
afinn <- pride_prejudice %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(score)) %>%
mutate(method = "AFINN")
View(afinn)
bing_and_nrc <- bind_rows(pride_prejudice %>%
inner_join(get_sentiments("bing")) %>%
mutate(method = "Bing et al."),
pride_prejudice %>%
inner_join(get_sentiments("nrc") %>%
filter(sentiment %in% c("positive",
"negative"))) %>%
mutate(method = "NRC")) %>%
count(method, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
View(bing_and_nrc)
get_sentiments("nrc")
a<-get_sentiments("nrc")
a[a$sentiment=="negative"]
a[a$sentiment=="negative",]
a[a$sentiment=="positive",]
View(bing_and_nrc)
bind_rows(afinn,
bing_and_nrc) %>%
ggplot(aes(index, sentiment, fill = method)) +
geom_col(show.legend = FALSE) +
facet_wrap(~method, ncol = 1, scales = "free_y")
custom_stop_words <- bind_rows(data_frame(word = c("miss"),
lexicon = c("custom")),
stop_words)
custom_stop_words
install.packages("wordcloud")
library(wordcloud)
tidy_books %>%
anti_join(stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100))
library(reshape2)
tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"),
max.words = 100)
PandP_sentences <- data_frame(text = prideprejudice) %>%
unnest_tokens(sentence, text, token = "sentences")
PandP_sentences$sentence[2]
bigrams_separated <- austen_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
austen_bigrams <- austen_books() %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigrams_separated <- austen_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bigrams_united <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ")
View(bigrams_united)
bigrams_separated %>%
filter(word1 == "not") %>%
count(word1, word2, sort = TRUE)
AFINN <- get_sentiments("afinn")
negated_words <- bigrams_separated %>%
filter(word1 %in% negation_words) %>%
inner_join(AFINN, by = c(word2 = "word")) %>%
count(word1, word2, score, sort = TRUE) %>%
ungroup()
negation_words <- c("not", "no", "never", "without")
negated_words <- bigrams_separated %>%
filter(word1 %in% negation_words) %>%
inner_join(AFINN, by = c(word2 = "word")) %>%
count(word1, word2, score, sort = TRUE) %>%
ungroup()
install.packages("tm")
?tapply
setwd("~/Data Science/5. Reproducible research")
amd <- read.csv("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip")
amd <- read.csv("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip")
amd <- read.csv("
https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip/activity.csv")
amd <- read.csv("
https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.csv")
amd <- read.csv("
https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip")
amd <- read.csv("
https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip")
amd <- read.csv("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip")
amd <- read.csv("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",
header=T, quote="\"", sep=",")
amd <- read.table("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",
header=T, quote="\"", sep=",")
amd <- read.csv("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",
header=T,  sep=",")
amd <- read.csv("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",
header=T,  sep=",")
View(amd)
amd <- read.table("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",
header=T,  sep=",")
View(amd)
rm(amd)
amd <- read.table("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",
header=T,  sep=",")
rm(amd)
amd <- read.table(unz("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",
"activity.csv"), header=T,  sep=",")
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",
"activity.zip")
setwd("~/Data Science/5. Reproducible research/Week2")
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip",
"activity.zip")
amd <- read.csv("acitivity.zip")
amd <- read.csv("activity.zip")
View(amd)
rm(amd)
amd <- read.csv(unz("activity.zip","activity.csv"))
View(amd)
?unzip
?unz
?unzip
amd2 <- read.table("activity.zip",header = T, sep = ",")
amd2 <- read.csv("activity.csv.zip")
amd2 <- read.csv("activity.csv.zip", raw=F)
amd2 <- read.csv("activity.zip/activity.csv")
amd2 <- read.csv("activity.zip")
rm(list)ls()
rm(list=ls())
amd <- read.csv(unz("activity.zip","activity.csv"))
View(amd)
str(amd)
amd <- read.csv(unz("activity.zip","activity.csv"), stringsAsFactors = F)
str(amd)
setwd("~/Git/RepData_PeerAssessment1")
dir
dir()
rm(amd)
amd <- read.csv(unz("activity.zip","activity.csv"), stringsAsFactors = F)
View(amd)
amd$date <- as.Date(amd$date)
View(amd)
str(amd)
?aggregate
totalStepPerDay <- tapply(amd$steps,amd$date,sum)
totalStepPerDay
totalStepPerDay <- tapply(amd$steps,amd$date,sum,na.rm=T)
totalStepPerDay
View(amd)
amd[amd$date=="2012-10-01",]
totalStepPerDay
amd[amd$date=="2012-11-10",]
hists(totalStepPerDay)
hist(totalStepPerDay)
hist(totalStepPerDay, fill = "green")
?hist
hist(totalStepPerDay, col = "green")
StepPerDay <- tapply(amd$steps,amd$date,sum,na.rm=T)
hist(StepPerDay, col = "green")
rm(totalStepPerDay)
rm(StepPerDay)
rm(StepPerDay)
StepsPerDay <- tapply(amd$steps,amd$date,sum,na.rm=T)
hist(StepsPerDay, col = "green")
median(StepsPerDay)
hist(StepsPerDay, col = "green")
MeanSteps <- mean(StepsPerDay)
MedSteps <- median(StepsPerDay)
hist(StepsPerDay, col = "green")
hist(StepsPerDay, col = "gray")
hist(StepsPerDay, col = "blue")
hist(StepsPerDay, col = "green")
with(amd, plot(steps,date,type=l))
with(amd, plot(steps,date,type="l""))
with(amd, plot(steps,date,type="l"))
?plot
plot(amd$steps,amd$date,type="l")
plot(amd$date,amd$steps,type="l")
with(amd, plot(date,steps,type="l"))
with(amd, plot(date, steps, type="l"))
MeanStepInterval <- tapply(amd$steps,amd$interval,mean,na.rm=T)
MeanStepInterval
plot(names(MeanStepInterval),MeanStepInterval,type="l")
plot(names(MeanStepInterval),MeanStepInterval,type="l",
xlab = "5 minute interval",
ylab = "Average number of steps per interval")
MaxInterval <- MeanStepInterval[MeanStepInterval==max(MeanStepInterval),]
MeanStepInterval == max(MeanStepInterval)
MeanStepInterval[MeanStepInterval==max(MeanStepInterval),]
MaxInterval <- MeanStepInterval[MeanStepInterval==max(MeanStepInterval)]
MaxInterval
MaxInterval <- names(MeanStepInterval[MeanStepInterval==max(MeanStepInterval)])
MaxInterval
plot(names(MeanStepInterval),MeanStepInterval,type="l",
xlab = "5 minute interval",
ylab = "Average number of steps per interval")
MaxIntName <- names(MaxInterval)
MaxInterval <- MeanStepInterval[MeanStepInterval==max(MeanStepInterval)]
MaxIntName <- names(MaxInterval)
plot(names(MeanStepInterval),MeanStepInterval,type="l",
xlab = "5 minute interval",
ylab = "Average number of steps per interval")
plot(names(MeanStepInterval),MeanStepInterval,type="l",
ylab = "Average number of steps per interval",
xlab = "5 minute interval",
col = "blue")
plot(names(MeanStepInterval),MeanStepInterval,type="l",
ylab = "Average number of steps per interval",
xlab = "5 minute interval",
col = "gray")
plot(names(MeanStepInterval),MeanStepInterval,type="l",
ylab = "Average number of steps per interval",
xlab = "5 minute interval",
col = "green")
TotNAs <- sum(is.na(amd$steps))
TotNAs
?impute
?imputeknn
?apply
?sapply
print(m)
for (m in is.na(amd$steps)) {
print(m)
}
Impute_amd <- amd
for (m in is.na(amd$steps)) {
Impute_amd[m,"Steps"] <- MeanStepInterval[m]
}
View(Impute_amd)
Impute_amd[1,]
Impute_amd[1,"Steps"] <- MeanStepInterval[1]
Impute_amd[1,]
MeanStepInterval[1]
View(Impute_amd)
rm(Impute_amd)
Impute_amd <- amd
for (m in is.na(amd$steps)) {
Impute_amd[m,"steps"] <- MeanStepInterval[m]
}
?lapply
for (m in is.na(amd$steps)) {
Impute_amd[m,"steps"] <- MeanStepInterval[m]
}
View(Impute_amd)
rm(Impute_amd)
Imputed_amd <- amd
for (m in is.na(amd$steps)) {
Imputed_amd[m,"steps"] <- MeanStepInterval[m]
}
MeanStepInterval[1]
Imputed_amd <- amd
Imputed_amd[is.na(Imputed_amd$steps)] <- MeanStepInterval[is.na(Imputed_amd$steps)]
Imputed_amd <- amd
View(Imputed_amd)
Imputed_amd[is.na(Imputed_amd$steps),"steps"] <-
MeanStepInterval[is.na(Imputed_amd$steps)]
View(Imputed_amd)
ImStepsPerDay <- tapply(Imputed_amd$steps, Imputed_amd$date,sum,na.rm=T)
ImMeanSteps <- mean(ImStepsPerDay)
ImMedSteps <- median(ImStepsPerDay)
hist(ImStepsPerDay, col = "purple")
?format
ImMedSteps
hist(ImStepsPerDay, col = "purple",
main = "Histogram of Steps per day",
xlab = "Steps per day")
hist(StepsPerDay, col = "green",
main = "Histogram of Steps per day",
xlab = "Steps per day")
?weekdays
weekdays(amd[1,"Date"])
weekdays(amd[1,"aate"])
weekdays(amd[1,"date"])
weekdays(amd[1,"Date"],TRUE)
weekdays(amd[1,"date"],TRUE)
?weekday
library(lubridate)
julian(amd[1,"date"],TRUE)
weekdays(amd[1,"date"],TRUE)
q()
